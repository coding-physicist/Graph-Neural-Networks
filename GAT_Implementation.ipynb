{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "title-cell",
   "metadata": {},
   "source": [
    "# Graph Attention Network (GAT) Implementation\n",
    "\n",
    "This notebook implements Graph Attention Networks (GATs) for node classification tasks using the Cora citation network dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "setup-section",
   "metadata": {},
   "source": [
    "## Setup and Data Loading\n",
    "\n",
    "Import necessary libraries and load the Cora citation network dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "imports",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Core libraries\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.nn import Linear, Dropout\n",
    "\n",
    "# PyTorch Geometric for graph neural networks\n",
    "from torch_geometric.datasets import Planetoid\n",
    "from torch_geometric.nn import GATv2Conv\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "torch.manual_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "data-loading",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Cora citation network dataset\n",
    "dataset = Planetoid(root='.', name='Cora')\n",
    "data = dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "data-exploration",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display dataset statistics\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(f\"{('CORA DATASET STATISTICS'):^50}\")\n",
    "print(\"=\"*50)\n",
    "print(f\"Dataset Name:      {dataset.name}\")\n",
    "print(f\"Number of Graphs:  {len(dataset):,}\")\n",
    "print(f\"Number of Nodes:   {data.x.shape[0]:,}\")\n",
    "print(f\"Number of Edges:   {data.edge_index.shape[1]:,}\")\n",
    "print(f\"Node Features:     {dataset.num_features}\")\n",
    "print(f\"Number of Classes: {dataset.num_classes}\")\n",
    "print(f\"Train Nodes:       {data.train_mask.sum().item():,}\")\n",
    "print(f\"Validation Nodes:  {data.val_mask.sum().item():,}\")\n",
    "print(f\"Test Nodes:        {data.test_mask.sum().item():,}\")\n",
    "print(\"=\"*50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "utils-section",
   "metadata": {},
   "source": [
    "## Utility Functions\n",
    "\n",
    "Helper functions for model training and evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "utils",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(y_pred, y_true):\n",
    "    \"\"\"Calculate classification accuracy\"\"\"\n",
    "    return torch.sum(y_pred == y_true) / len(y_true)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "model-section",
   "metadata": {},
   "source": [
    "## Graph Attention Network (GAT)\n",
    "\n",
    "Implementation of Graph Attention Network using PyTorch Geometric with multi-head attention."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "gat-model",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GAT(torch.nn.Module):\n",
    "    \"\"\"Graph Attention Network for node classification\"\"\"\n",
    "    \n",
    "    def __init__(self, dim_in, dim_h, dim_out, heads=8):\n",
    "        super().__init__()\n",
    "        self.gat1 = GATv2Conv(dim_in, dim_h, heads=heads)  # First GAT layer with multi-head attention\n",
    "        self.gat2 = GATv2Conv(dim_h * heads, dim_out, heads=1)  # Second GAT layer (single head for output)\n",
    "        self.dropout = Dropout(0.6)  # Higher dropout for GAT\n",
    "    \n",
    "    def forward(self, x, edge_index):\n",
    "        # Apply dropout to input features\n",
    "        h = self.dropout(x)\n",
    "        \n",
    "        # First GAT layer with ELU activation\n",
    "        h = self.gat1(h, edge_index)\n",
    "        h = F.elu(h)\n",
    "        h = self.dropout(h)\n",
    "        \n",
    "        # Second GAT layer\n",
    "        h = self.gat2(h, edge_index)\n",
    "        return F.log_softmax(h, dim=1)\n",
    "    \n",
    "    def fit(self, data, epochs):\n",
    "        \"\"\"Train the GAT model\"\"\"\n",
    "        criterion = torch.nn.CrossEntropyLoss()\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=0.01, weight_decay=0.01)\n",
    "        \n",
    "        self.train()\n",
    "        print(\"\\n\" + \"=\"*60)\n",
    "        print(f\"{('Training Graph Attention Network'):^60}\")\n",
    "        print(\"=\"*60)\n",
    "        print(f\"{('Epoch'):>5} {('Train Loss'):>12} {('Train Acc'):>12} {('Val Loss'):>12} {('Val Acc'):>12}\")\n",
    "        print(\"-\"*60)\n",
    "        \n",
    "        for epoch in range(epochs + 1):\n",
    "            optimizer.zero_grad()\n",
    "            out = self(data.x, data.edge_index)\n",
    "            loss = criterion(out[data.train_mask], data.y[data.train_mask])\n",
    "            acc = accuracy(out[data.train_mask].argmax(dim=1), data.y[data.train_mask])\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            if epoch % 20 == 0:\n",
    "                val_loss = criterion(out[data.val_mask], data.y[data.val_mask])\n",
    "                val_acc = accuracy(out[data.val_mask].argmax(dim=1), data.y[data.val_mask])\n",
    "                print(f\"{epoch:5d} {loss.item():12.4f} {acc.item()*100:11.2f}% {val_loss.item():12.4f} {val_acc.item()*100:11.2f}%\")\n",
    "        \n",
    "        print(\"-\"*60)\n",
    "    \n",
    "    @torch.no_grad()\n",
    "    def test(self, data):\n",
    "        \"\"\"Evaluate on test set\"\"\"\n",
    "        self.eval()\n",
    "        out = self(data.x, data.edge_index)\n",
    "        acc = accuracy(out[data.test_mask].argmax(dim=1), data.y[data.test_mask])\n",
    "        return acc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "training-section",
   "metadata": {},
   "source": [
    "## Model Training and Evaluation\n",
    "\n",
    "Initialize, train and evaluate the GAT model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "model-init",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize GAT model\n",
    "gat = GAT(dataset.num_features, 32, dataset.num_classes, heads=8)\n",
    "\n",
    "print(\"\\n\" + \"=\"*40)\n",
    "print(f\"{('GAT ARCHITECTURE'):^40}\")\n",
    "print(\"=\"*40)\n",
    "print(gat)\n",
    "print(f\"Total Parameters: {sum(p.numel() for p in gat.parameters()):,}\")\n",
    "print(f\"Attention Heads (Layer 1): 8\")\n",
    "print(f\"Attention Heads (Layer 2): 1\")\n",
    "print(\"=\"*40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "model-training",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train GAT model\n",
    "gat.fit(data, 100)\n",
    "\n",
    "# Test the model\n",
    "gat_test_acc = gat.test(data)\n",
    "\n",
    "print(f\"\\n{('='*30)}\")\n",
    "print(f\"{('GAT FINAL RESULTS'):^30}\")\n",
    "print(f\"{('='*30)}\")\n",
    "print(f\"Test Accuracy: {gat_test_acc.item()*100:6.2f}%\")\n",
    "print(f\"{('='*30)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
